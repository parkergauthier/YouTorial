{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amalkadri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x136268910>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import ssl\n",
    "import spacy\n",
    "import nltk.corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "conn_string = # \"redacted due to credential exposure\" \n",
    "engine = sqlalchemy.create_engine(conn_string)\n",
    "\n",
    "sql_data = pd.read_sql_table('youtube_metrics',engine)\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"spacytextblob\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>videoID</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>You always publish the best videos, I have a q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Great videos. They've helped me paint my 3,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Great Job Chris! Very good work, thanks for sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>I would love to see how you mix the lacquer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Great video! Would be cool to see more on your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>I love your channel good job,just a quick ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Chris,\\n\\nI am looking at spraying some Built-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Excellent video. Would also like to how you cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Is there any difference in the cleaning proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>What sizes of FFLP fine finish do you like to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Thanks for the vid, I'm wondering if you use t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Brown masking paper instead of green?  I know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Hi Chris,\\nWhen you paint a door like these, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Used to spray lacquer in new custom homes in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Do you need anything special for your sprayer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>I forgot to mention that you have the best How...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Great video! Thanks Chris!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>I was curious y u spray the cut in last ? I‚Äôm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Do you add anything to the hi build laquor or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>What works best for cleaning your Air Gun afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>can these sprayers be used to spray with polyu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>you spray the stain ?\\nspray stain or spray a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>What type of  sanding sealer are you using !!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Hi Cress this is Ahmed From Egypt i watch almo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>KjPDJLlzirM</td>\n",
       "      <td>Hey man, Bit of a fan! I'm a painter and decor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      videoID                                            comment\n",
       "0       3  KjPDJLlzirM  You always publish the best videos, I have a q...\n",
       "1       1  KjPDJLlzirM  Great videos. They've helped me paint my 3,000...\n",
       "2       2  KjPDJLlzirM  Great Job Chris! Very good work, thanks for sh...\n",
       "3       4  KjPDJLlzirM       I would love to see how you mix the lacquer.\n",
       "4       0  KjPDJLlzirM  Great video! Would be cool to see more on your...\n",
       "5       5  KjPDJLlzirM  I love your channel good job,just a quick ques...\n",
       "6       6  KjPDJLlzirM  Chris,\\n\\nI am looking at spraying some Built-...\n",
       "7       7  KjPDJLlzirM  Excellent video. Would also like to how you cl...\n",
       "8       8  KjPDJLlzirM  Is there any difference in the cleaning proces...\n",
       "9       9  KjPDJLlzirM  What sizes of FFLP fine finish do you like to ...\n",
       "10     10  KjPDJLlzirM  Thanks for the vid, I'm wondering if you use t...\n",
       "11     11  KjPDJLlzirM  Brown masking paper instead of green?  I know ...\n",
       "12     12  KjPDJLlzirM  Hi Chris,\\nWhen you paint a door like these, a...\n",
       "13     13  KjPDJLlzirM  Used to spray lacquer in new custom homes in t...\n",
       "14     14  KjPDJLlzirM  Do you need anything special for your sprayer ...\n",
       "15     15  KjPDJLlzirM  I forgot to mention that you have the best How...\n",
       "16     16  KjPDJLlzirM                         Great video! Thanks Chris!\n",
       "17     17  KjPDJLlzirM  I was curious y u spray the cut in last ? I‚Äôm ...\n",
       "18     18  KjPDJLlzirM  Do you add anything to the hi build laquor or ...\n",
       "19     19  KjPDJLlzirM  What works best for cleaning your Air Gun afte...\n",
       "20     20  KjPDJLlzirM  can these sprayers be used to spray with polyu...\n",
       "21     21  KjPDJLlzirM  you spray the stain ?\\nspray stain or spray a ...\n",
       "22     22  KjPDJLlzirM     What type of  sanding sealer are you using !!!\n",
       "23     23  KjPDJLlzirM  Hi Cress this is Ahmed From Egypt i watch almo...\n",
       "24     24  KjPDJLlzirM  Hey man, Bit of a fan! I'm a painter and decor..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_data\n",
    "metrics = sql_data.iloc[0].to_dict()\n",
    "analysis = {\n",
    "    'videoID' : metrics['videoID'],\n",
    "    'views_count' : int(metrics['views']),\n",
    "    'likes': int(metrics['likes']),\n",
    "    'comments_' : int(metrics['comments']),\n",
    "    'length_' : metrics['length'],\n",
    "    'like_ratios' : int(metrics['likes'])/int(metrics['views']),\n",
    "    'comment_ratio' : int(metrics['comments'])/int(metrics['views'])\n",
    "}\n",
    "analysis\n",
    "\n",
    "def sql_comments(video):\n",
    "    \"\"\"gets comments from comments database\"\"\"\n",
    "    sql_comm = pd.read_sql(f\"\"\"select * from youtube_comments where \"videoID\" = '{video}'\"\"\", engine).drop_duplicates()\n",
    "    return sql_comm\n",
    "\n",
    "sql_comments(\"KjPDJLlzirM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_sql_table('youtube_comments',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>videoID</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, this is very impressive! I‚Äôm watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, Thanks for sharing this informativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, excellent video absolutely loved i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Thanks, Brother. This was a bit intricate for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>One of the best Analysis video I have seen so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124983</th>\n",
       "      <td>5</td>\n",
       "      <td>pJiYw2pUceg</td>\n",
       "      <td>Gorgeous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124984</th>\n",
       "      <td>6</td>\n",
       "      <td>pJiYw2pUceg</td>\n",
       "      <td>Sick video. This is the best Bloody Mary mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124985</th>\n",
       "      <td>7</td>\n",
       "      <td>pJiYw2pUceg</td>\n",
       "      <td>sweetüòãüòöüëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124986</th>\n",
       "      <td>8</td>\n",
       "      <td>pJiYw2pUceg</td>\n",
       "      <td>this‚ù§‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124987</th>\n",
       "      <td>9</td>\n",
       "      <td>pJiYw2pUceg</td>\n",
       "      <td>üòâüòâüòâüòâ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124988 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index      videoID                                            comment\n",
       "0           0  SwSbnmqk3zY  Hi Thoufiq, this is very impressive! I‚Äôm watch...\n",
       "1           1  SwSbnmqk3zY  Hi Thoufiq, Thanks for sharing this informativ...\n",
       "2           2  SwSbnmqk3zY  Hi Thoufiq, excellent video absolutely loved i...\n",
       "3           3  SwSbnmqk3zY  Thanks, Brother. This was a bit intricate for ...\n",
       "4           4  SwSbnmqk3zY  One of the best Analysis video I have seen so ...\n",
       "...       ...          ...                                                ...\n",
       "124983      5  pJiYw2pUceg                                           Gorgeous\n",
       "124984      6  pJiYw2pUceg       Sick video. This is the best Bloody Mary mix\n",
       "124985      7  pJiYw2pUceg                                           sweetüòãüòöüëç\n",
       "124986      8  pJiYw2pUceg                                             this‚ù§‚ù§\n",
       "124987      9  pJiYw2pUceg                                               üòâüòâüòâüòâ\n",
       "\n",
       "[124988 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‚Äò‚Äô‚Äú‚Äù‚Ä¶]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, this is very impressive! I‚Äôm watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_xNI6tuOeI</td>\n",
       "      <td>Very Impressive finishing work. Nice to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vGJL0BgVMOw</td>\n",
       "      <td>perfect taste combination... gonna try this re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ianApRDflh0</td>\n",
       "      <td>Here‚Äôs the potato harvest! https://youtu.be/UK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8nQUQJKnX0E</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K4a3dTScBlg</td>\n",
       "      <td>Having a toilet was must for our camper van an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pb4xXXEA8zk</td>\n",
       "      <td>Girl!! You are on a serious streak with these ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoID                                            comment\n",
       "0  SwSbnmqk3zY  Hi Thoufiq, this is very impressive! I‚Äôm watch...\n",
       "1  B_xNI6tuOeI  Very Impressive finishing work. Nice to see th...\n",
       "2  vGJL0BgVMOw  perfect taste combination... gonna try this re...\n",
       "3  ianApRDflh0  Here‚Äôs the potato harvest! https://youtu.be/UK...\n",
       "4  8nQUQJKnX0E                                               Good\n",
       "5  K4a3dTScBlg  Having a toilet was must for our camper van an...\n",
       "6  pb4xXXEA8zk  Girl!! You are on a serious streak with these ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_analysis = comments_df[['videoID','comment']].drop_duplicates().head(100)\n",
    "comm_analysis['comment'] = comm_analysis.groupby(['videoID'])['comment'].transform(lambda x : ' '.join(x))\n",
    "comm_analysis = comm_analysis.drop_duplicates().reset_index()[['videoID','comment']]\n",
    "comm_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_analysis['clean'] =  comm_analysis['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "comm_analysis['clean'] = comm_analysis['clean'].transform(lambda txt: clean_text_round1(txt)).transform(lambda txt: clean_text_round2(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30122663921444404"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = comm_analysis['clean'][0]\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"spacytextblob\")\n",
    "nlp(text)\n",
    "nlp(text)._.blob.polarity\n",
    "get_polarity(text)\n",
    "# print(doc._.blob.polarity)\n",
    "# print(doc._.blob.subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(txt):\n",
    "    return nlp(txt)._.blob.polarity\n",
    "polarity_getter = get_polarity\n",
    "def get_subjectivity(txt):\n",
    "    return nlp(txt)._.blob.subjectivity\n",
    "subjectivity_getter = get_subjectivity\n",
    "\n",
    "def get_sentiment(txt):\n",
    "    doc = nlp(txt)\n",
    "    sentiment_list = [doc._.blob.polarity,doc._.blob.subjectivity]\n",
    "    return sentiment_list\n",
    "sentiment_getter = get_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>comment</th>\n",
       "      <th>clean</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, this is very impressive! I‚Äôm watch...</td>\n",
       "      <td>hi thoufiq impressive im watching purely curio...</td>\n",
       "      <td>0.301227</td>\n",
       "      <td>0.545183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_xNI6tuOeI</td>\n",
       "      <td>Very Impressive finishing work. Nice to see th...</td>\n",
       "      <td>very impressive finishing work nice see pride ...</td>\n",
       "      <td>0.352873</td>\n",
       "      <td>0.541713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vGJL0BgVMOw</td>\n",
       "      <td>perfect taste combination... gonna try this re...</td>\n",
       "      <td>perfect taste combination gonna try recipe üòãüòãn...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ianApRDflh0</td>\n",
       "      <td>Here‚Äôs the potato harvest! https://youtu.be/UK...</td>\n",
       "      <td>heres potato harvest httpsyoutubeukmsnboeofe i...</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.480078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8nQUQJKnX0E</td>\n",
       "      <td>Good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K4a3dTScBlg</td>\n",
       "      <td>Having a toilet was must for our camper van an...</td>\n",
       "      <td>having toilet must camper van were super happy...</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.486941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pb4xXXEA8zk</td>\n",
       "      <td>Girl!! You are on a serious streak with these ...</td>\n",
       "      <td>girl you serious streak last few i mean i love...</td>\n",
       "      <td>0.120417</td>\n",
       "      <td>0.537083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoID                                            comment  \\\n",
       "0  SwSbnmqk3zY  Hi Thoufiq, this is very impressive! I‚Äôm watch...   \n",
       "1  B_xNI6tuOeI  Very Impressive finishing work. Nice to see th...   \n",
       "2  vGJL0BgVMOw  perfect taste combination... gonna try this re...   \n",
       "3  ianApRDflh0  Here‚Äôs the potato harvest! https://youtu.be/UK...   \n",
       "4  8nQUQJKnX0E                                               Good   \n",
       "5  K4a3dTScBlg  Having a toilet was must for our camper van an...   \n",
       "6  pb4xXXEA8zk  Girl!! You are on a serious streak with these ...   \n",
       "\n",
       "                                               clean  polarity  subjectivity  \n",
       "0  hi thoufiq impressive im watching purely curio...  0.301227      0.545183  \n",
       "1  very impressive finishing work nice see pride ...  0.352873      0.541713  \n",
       "2  perfect taste combination gonna try recipe üòãüòãn...  0.600000      0.920000  \n",
       "3  heres potato harvest httpsyoutubeukmsnboeofe i...  0.271048      0.480078  \n",
       "4                                               good  0.700000      0.600000  \n",
       "5  having toilet must camper van were super happy...  0.237805      0.486941  \n",
       "6  girl you serious streak last few i mean i love...  0.120417      0.537083  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text_analysis = comm_analysis\n",
    "final_text_analysis['polarity'] = final_text_analysis['clean'].apply(polarity_getter)\n",
    "final_text_analysis['subjectivity'] = final_text_analysis['clean'].apply(subjectivity_getter)\n",
    "final_text_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/lvwyjtw159jgvq01xkgtwzj00000gn/T/ipykernel_25120/3171715115.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_text_analysis[['polarity','subjectivity']] = pd.DataFrame(final_text_analysis['clean'].apply(sentiment_getter).to_list(), columns =['polarity','subjectivity'])\n",
      "/var/folders/18/lvwyjtw159jgvq01xkgtwzj00000gn/T/ipykernel_25120/3171715115.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_text_analysis[['polarity','subjectivity']] = pd.DataFrame(final_text_analysis['clean'].apply(sentiment_getter).to_list(), columns =['polarity','subjectivity'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>clean</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>hi thoufiq impressive im watching purely curio...</td>\n",
       "      <td>0.301227</td>\n",
       "      <td>0.545183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_xNI6tuOeI</td>\n",
       "      <td>very impressive finishing work nice see pride ...</td>\n",
       "      <td>0.352873</td>\n",
       "      <td>0.541713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vGJL0BgVMOw</td>\n",
       "      <td>perfect taste combination gonna try recipe üòãüòãn...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ianApRDflh0</td>\n",
       "      <td>heres potato harvest httpsyoutubeukmsnboeofe i...</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.480078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8nQUQJKnX0E</td>\n",
       "      <td>good</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K4a3dTScBlg</td>\n",
       "      <td>having toilet must camper van were super happy...</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.486941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pb4xXXEA8zk</td>\n",
       "      <td>girl you serious streak last few i mean i love...</td>\n",
       "      <td>0.120417</td>\n",
       "      <td>0.537083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoID                                              clean  polarity  \\\n",
       "0  SwSbnmqk3zY  hi thoufiq impressive im watching purely curio...  0.301227   \n",
       "1  B_xNI6tuOeI  very impressive finishing work nice see pride ...  0.352873   \n",
       "2  vGJL0BgVMOw  perfect taste combination gonna try recipe üòãüòãn...  0.600000   \n",
       "3  ianApRDflh0  heres potato harvest httpsyoutubeukmsnboeofe i...  0.271048   \n",
       "4  8nQUQJKnX0E                                               good  0.700000   \n",
       "5  K4a3dTScBlg  having toilet must camper van were super happy...  0.237805   \n",
       "6  pb4xXXEA8zk  girl you serious streak last few i mean i love...  0.120417   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.545183  \n",
       "1      0.541713  \n",
       "2      0.920000  \n",
       "3      0.480078  \n",
       "4      0.600000  \n",
       "5      0.486941  \n",
       "6      0.537083  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text_analysis = comm_analysis[['videoID','clean']]\n",
    "final_text_analysis[['polarity','subjectivity']] = pd.DataFrame(final_text_analysis['clean'].apply(sentiment_getter).to_list(), columns =   ['polarity','subjectivity'])\n",
    "final_text_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'videoID': 'SwSbnmqk3zY',\n",
       " 'clean': 'hi thoufiq impressive im watching purely curiosity bc ive started python class yet however i would love see sql project ideas maybe data cleaning andor analysis thanks always clear explanations guidance üëçüèª also glad see youre closing  friend congratulations advance üòÄüëåüèªüôèüèª hi thoufiq thanks sharing informative  interesting video i wondering extract actual comments replies instead comment count example thanks advance hi thoufiq excellent video absolutely loved please keep creating many project videos can make short video visualize data using python dynamic radar charts ie player vs player comparisioncompany vs company  filter two competitors compare thanks brother this bit intricate i started learning python data analysis tricks used new i eager learn use create new project based information dont worry keep it bigger ken jee one day stay consistent one best analysis video i seen far amazing content  expecting videos projects  appreciate hard work  hi great tutorial congratulations work it really helped lot know work youtube api hi thoufiq useful video content really helpful people like us freshers want pursue career data analytics actually i trying project stucked jupyter notebook it show virtual environment kernal created project i tried solve problem installing ipy kernal displaying kernal name still notebook show virtual environment kernal created can please help this hi thoufiq great tutorial just getting started python one quick question i see ytenv jupyter notebook start jupyter ytenv terminal any idea went wrong kind regards stephan great tutorial thanks bro also would highly appreciate if make similar video how grab viewers data i looking extracting periodical data day week month etc viewership subscribers comments likes  dislikes etc user export google sheet rendering process further references sources subject referred shall highly appreciated was waiting thisüòÉthanks lot brother helpful videoüëåüèª way goüôåüèª thanks lot video üòäüòä btw liked ofc already subscribed please upload videos projects hi thoufiq great job doing absolutely love this id like know worked getting channel ids youtubers based location country ie all channel ids country also working project i got errors reason playlistnotfound trying access video ids using playlist ids i unable go passed that any idea issue might be thanks educative content kind regards hey taufiq prepareask questions practicing sql datasets elaborate detail upcoming videos thank brother great tutorial good explanation worked me please make video extract comments likes dislikes comment user name comment date help lot thank great explanation fab always concise fleek keep upüëåüèªüëåüèªüôè excellent work great explanation sir waiting challenging videos really interested stuff fabulous explanation also please videos data science begin scratch üôåüôå i used c sql programmer i retired i want download comments i made years different youtube table database i store locally you seem done exactly i need do can i access necessary codes i copy paste i grateful thank you awesome tutorial üî•üòé amazing video thank much i would like know get video details multiple channels time can please suggest it thanks informative video get comments  personal youtube channel permission using api and can data stored text file realtime great class bro  thank much this i got issue though i run project visual studio i added  links analyze  channels instead  shows  it shows errors  indexerror traceback most recent call last cusersutenteappdatalocalprogramspythonytanalysisprojectipynb cell  module   playlistid  channeldatalocken jee playlistidiloc file  locationindexergetitemself key  axis  selfaxis   maybecallable  comapplyifcallablekey selfobj   return selfgetitemaxismaybecallable axisaxis file  ilocindexergetitemaxisself key axis  raise typeerrorcannot index location index noninteger key   validate location   selfvalidateintegerkey axis  return selfobjixskey axisaxis file  ilocindexervalidateintegerself key axis  lenaxis  lenselfobjgetaxisaxis  key  lenaxis key  lenaxis   raise indexerrorsingle positional indexer outofbounds indexerror single positional indexer outofbounds can help please thanks valuable information you brilliant ü•≥ü•≥ü•≥üôèüôèüíê',\n",
       " 'polarity': 0.30122663921444404,\n",
       " 'subjectivity': 0.5451834547566256}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_dict = final_text_analysis.iloc[0].to_dict()\n",
    "row_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11bc5473a089e76c07066961afaead49486381ca340fa51be560f4147a3f600d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
